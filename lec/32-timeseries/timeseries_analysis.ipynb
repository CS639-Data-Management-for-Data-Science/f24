{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "701eb825-7b07-4b8d-a395-25b01f56b585",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install plotly --upgrade\n",
    "!pip install statsmodels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfbb7190-37fc-4f77-bfad-ce72237d92bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ab9956-1d5b-4a31-809b-7a21ea86160b",
   "metadata": {},
   "source": [
    "### Retailrocket recommender system dataset\n",
    "\n",
    "Source: https://www.kaggle.com/retailrocket/ecommerce-dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35f6d898-108e-46e4-8ea2-0628fc5375ea",
   "metadata": {},
   "source": [
    "Load the dataset files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcca2cd5-7f27-485d-80b7-68d1e24f4c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "events = pd.read_csv(os.path.join('data', 'events.csv'))\n",
    "item_properties = pd.read_csv(os.path.join('data', 'item_properties_part1.csv'))\n",
    "category_tree = pd.read_csv(os.path.join('data', 'category_tree.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01fd0ab3-0f87-4cae-ae6a-28cf289498f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f3deb63-562e-43cb-a981-aa74bf7405d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "827fffa1-1b9d-4fb8-bb33-4eee8fc7302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af90dbac-976b-4af2-a754-83da7f48d1e1",
   "metadata": {},
   "source": [
    "#### Q1: Convert `parentid` column to `int32` type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6152bc87-407a-46f7-90ab-2fd7251dc7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c611e0bf-3ec2-4edb-bab6-ace49200fdb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_tree_v2 = category_tree.copy()\n",
    "category_tree_v3 = category_tree.copy()\n",
    "category_tree_v4 = category_tree.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459d637f-37db-41ac-b486-fa6e0db74d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_tree_v2.parentid = category_tree2.parentid.astype(\"int32\")\n",
    "category_tree_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2902c01d-4929-4e16-8293-6c2bd58d45df",
   "metadata": {},
   "source": [
    "## Data imputation\n",
    "\n",
    "a process that replaces missing values in a dataset with substituted values\n",
    "\n",
    "### Handling missing values with `category_tree`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a1049b3-32df-4142-aa37-0979850ed55f",
   "metadata": {},
   "source": [
    "#### Option 1: Fill `NaN` with a placeholder value (e.g., -1 or another integer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba9f19d6-201c-4960-890d-23f411e6402c",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_tree_v2['parentid'] = category_tree['parentid'].fillna(-1).astype(\"int32\")\n",
    "category_tree_v2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7996cb9-d4f8-4982-81d1-bc0bb4bdd15a",
   "metadata": {},
   "source": [
    "#### Option 2: Drop rows with `NaN` in the `parentid `column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cff3811b-4ce0-4c9a-b46d-0209a30f4b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_tree_v3 = category_tree_v3.dropna(subset=['parentid'])\n",
    "\n",
    "category_tree_v3.parentid = category_tree_v3.parentid.astype(\"int32\")\n",
    "category_tree_v3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "795453cb-83c1-4f88-95b3-ed61f98f47d3",
   "metadata": {},
   "source": [
    "#### Option 3: Use `Int32` (nullable integer type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c16b86e4-9c84-4b16-9af2-b3cd914e3063",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_tree_v4['parentid'] = category_tree_v4['parentid'].astype(\"Int32\")\n",
    "category_tree_v4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b39f2a1-6e57-4adb-9a66-e492878957aa",
   "metadata": {},
   "source": [
    "### Other options for Data Imputation\n",
    "\n",
    "- Next or previous value\n",
    "- Maximum or Minimum Value\n",
    "- Statistical methods: mean, median, mode\n",
    "- Missing Value Prediction: using a machine learning model to determine the final imputation value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6e0d7a-9ede-41af-893c-d5e08fcb87b9",
   "metadata": {},
   "source": [
    "Replace with next value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07334953-2b72-47a5-94ba-abe719480f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(639)\n",
    "\n",
    "date_range = pd.date_range(start='2024-01-01', periods=15, freq='D')\n",
    "sales_data = np.random.normal(loc=200, scale=20, size=len(date_range))\n",
    "sales_data[::5] = np.nan  # missing value every 5th day\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'sales': sales_data\n",
    "})\n",
    "print(df)\n",
    "\n",
    "df = df.bfill()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef238609-fbf9-408b-9797-80452792224e",
   "metadata": {},
   "source": [
    "Replace with previous value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b336b16a-a5eb-477a-a6a2-301afbb2cc95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'sales': sales_data\n",
    "})\n",
    "print(df)\n",
    "\n",
    "df = df.ffill()\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70c20aae-8b64-41fc-a8a5-ccf5b3df9724",
   "metadata": {},
   "source": [
    "Replace with minimum / maximum."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e5b9bc4-1de3-4c03-9f5c-c8e6ee7495d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'sales': sales_data\n",
    "})\n",
    "print(df)\n",
    "\n",
    "df = df.fillna(df.sales.min()) # or max() for maximum\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff643e31-d202-461e-a83c-55eaa34aaf87",
   "metadata": {},
   "source": [
    "Replace with mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54699bdd-f3b9-488b-a47a-81c6d83ee512",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'sales': sales_data\n",
    "})\n",
    "print(df)\n",
    "\n",
    "df = df.fillna(df.sales.mean())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "517eb311-81dc-4244-8a84-1cd097fc60b5",
   "metadata": {},
   "source": [
    "Replace with median."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5facfd74-e6f7-44a7-b94e-4591f1e5bf44",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'sales': sales_data\n",
    "})\n",
    "print(df)\n",
    "\n",
    "df = df.fillna(df.sales.median())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649eee3a-3e46-4359-8c30-b572cdd8c10c",
   "metadata": {},
   "source": [
    "Replace with mode."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44902e21-f452-4094-9be1-8479a35a3114",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(639)\n",
    "\n",
    "date_range = pd.date_range(start='2024-01-01', periods=15, freq='D')\n",
    "values = [100, 150, 200, 250]\n",
    "sales_data = np.random.choice(values, size=15).tolist()\n",
    "\n",
    "for i in range(0, len(data), 5):\n",
    "    sales_data[i] = np.nan\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'sales': sales_data\n",
    "})\n",
    "print(df)\n",
    "\n",
    "df = df.fillna(df.sales.mode().iloc[0])\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "939d51c6-d30c-4bc7-909e-8428e2323530",
   "metadata": {},
   "source": [
    "### Data Interpolation\n",
    "\n",
    "Interpolation is a technique that can be useful for handling missing values, particularly when the missing data is assumed to follow a pattern or trend based on the existing values in the dataset. This is often the case with time series or ordered data, where the missing values are assumed to lie between known values. Interpolation fills in these gaps by estimating the missing data points using existing values.\n",
    "\n",
    "When **NOT** to Use Interpolation:\n",
    "- Large gaps: If the data has large gaps between observations, interpolation might not provide meaningful or reliable estimates.\n",
    "- Randomness in missing values: If the missing values are random or don't follow any pattern (Missing Completely at Random - MCAR), interpolation may not be appropriate, as it assumes a relationship between values.\n",
    "- Categorical or non-numeric data: Interpolation is typically used for continuous numerical data. For categorical or binary data, interpolation is not suitable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "614094a1-c683-4639-9730-671f28cf4377",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(639)\n",
    "\n",
    "date_range = pd.date_range(start='2024-01-01', periods=60, freq='D')\n",
    "sales_data = np.random.normal(loc=200, scale=20, size=len(date_range))\n",
    "sales_data[::5] = np.nan  # missing value every 5th day\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'sales': sales_data\n",
    "})\n",
    "print(df.head())\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['date'], df['sales'], marker='o', linestyle='-', color='black')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Sales')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d281264f-8257-488c-a682-9465f271fabf",
   "metadata": {},
   "source": [
    "### Linear interpolation\n",
    "\n",
    "- Assumption: the missing data points lie along a straight line between the known data points.\n",
    "- Linear interpolation commonly used for time series where changes are expected to be linear between data points.\n",
    "- When to use: when the relationship between consecutive values is roughly linear or changes gradually."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466baa12-f3f4-4347-b39c-c93ebdc86a22",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sales'] = df['sales'].interpolate(method='linear')\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['date'], df['sales'], marker='o', linestyle='-', label='Interpolated Sales', color='orange')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d2bdf4-1048-44f7-bf98-5fa1faa6a8d5",
   "metadata": {},
   "source": [
    "### Polynomial interpolation\n",
    "\n",
    "- Polynomial interpolation fits a polynomial curve through the known data points and uses it to estimate the missing values.\n",
    "- When to use: when the data shows a nonlinear relationship between points (for example, seasonal effects or periodic patterns)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17df91f-c94b-4df3-a6cc-3ce0bdac8e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['sales'] = df['sales'].interpolate(method='polynomial', order=2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['date'], df['sales'], marker='o', linestyle='-', label='Interpolated Sales', color='orange')\n",
    "plt.xticks(rotation=45)\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330dc155-a468-439b-b466-55cf27fbe640",
   "metadata": {},
   "source": [
    "#### Why do both methods produced the same result?\n",
    "\n",
    "- Polynomial interpolation of order 2 fits a quadratic function (a parabola) between the two surrounding data points.\n",
    "- A quadratic function can curve, but for the simple case where the data points are relatively close to each other and do not exhibit any highly nonlinear or curving behavior, the quadratic curve might end up being very similar to the straight line in terms of interpolation.\n",
    "- When there are only two points surrounding the missing value (as is typical with simple time series data), the quadratic interpolation will essentially behave like a linear interpolation because a second-degree polynomial (a parabola) that passes through two points is uniquely determined by those two points and does not \"bend\" between them in a noticeable way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72189d66-40e3-4fe6-93c3-1a960b507b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non-linear timeseries - sine curve\n",
    "np.random.seed(42)\n",
    "date_range = pd.date_range(start='2024-01-01', periods=60, freq='D')\n",
    "sales_data = 100 + 50 * np.sin(np.linspace(0, 3 * np.pi, len(date_range)))\n",
    "\n",
    "# Introduce missing values randomly\n",
    "missing_indices = np.random.choice(range(len(sales_data)), size=18, replace=False)\n",
    "sales_data[missing_indices] = np.nan\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'sales': sales_data\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['date'], df['sales'], marker='o', linestyle='-', label='Original Sales with Missing Values')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Sales')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71800e4e-079c-4626-951d-6c3f4e2c5794",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate using linear method\n",
    "df['sales_linear'] = df['sales'].interpolate(method='linear')\n",
    "\n",
    "# Interpolate using polynomial method (order 2)\n",
    "df['sales_polynomial'] = df['sales'].interpolate(method='polynomial', order=2)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['date'], df['sales_linear'], marker='o', linestyle='-', label='Interpolated Sales (Linear)', color='orange')\n",
    "plt.plot(df['date'], df['sales_polynomial'], marker='x', linestyle='-', label='Interpolated Sales (Polynomial)', color='green')\n",
    "plt.legend()\n",
    "plt.title('Linear vs Polynomial Interpolation on Nonlinear Data')\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54ff649e-680f-4a39-a0e0-4692ca3aa4d8",
   "metadata": {},
   "source": [
    "### Spline interpolation\n",
    "\n",
    "- Spline interpolation fits a smooth curve (a piecewise polynomial, typically cubic) through the known data points and estimates the missing values.\n",
    "- When to use: when the data exhibits a smooth, nonlinear trend (often used for time series with cycles or seasonal patterns).\n",
    "\n",
    "### Spline vs Polynomial\n",
    "\n",
    "- When to use spline interpolation: when you need smooth, piecewise fits, especially when the data is non-linear or has noise. It's ideal for smooth, continuous data that needs to be modeled accurately across a range of values.\n",
    "- When to use polynomial interpolation: when you have a simple, small dataset, and you want a single polynomial that fits all points exactly. Avoid polynomial interpolation with large or noisy datasets because it can cause overfitting and oscillations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "468db259-1ff3-47cb-a3c0-338a5de2ef4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(639)\n",
    "date_range = pd.date_range(start='2024-01-01', periods=60, freq='D')\n",
    "sales_data = 100 * np.sin(np.linspace(0, 3 * np.pi, len(date_range))) \n",
    "\n",
    "# Introduce missing values randomly\n",
    "missing_indices = np.random.choice(range(5, len(sales_data), 5), size=10, replace=False)\n",
    "sales_data[missing_indices] = np.nan\n",
    "\n",
    "df = pd.DataFrame({\n",
    "    'date': date_range,\n",
    "    'sales': sales_data\n",
    "})\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(df['date'], df['sales'], marker='o', linestyle='-', label='Original Sales with Missing Values', color='blue')\n",
    "plt.xticks(rotation=45)\n",
    "plt.ylabel('Sales')\n",
    "plt.grid(True)\n",
    "\n",
    "# Interpolate using cubic spline method\n",
    "df['sales_spline'] = df['sales'].interpolate(method='spline', order=3)\n",
    "\n",
    "plt.plot(df['date'], df['sales_spline'], marker='x', linestyle='-', label='Interpolated Sales (Spline)', color='green')\n",
    "plt.legend()\n",
    "plt.title('Spline Interpolation on Sinusoidal Data')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c706bcfc-6e7f-4013-9c10-0ccc26b57529",
   "metadata": {},
   "source": [
    "## Exploratory Data Analysis (EDA)\n",
    "\n",
    "EDA is about understanding the data and forming hypotheses about it. \n",
    "\n",
    "- Visualizing Data: Histograms, scatter plots, box plots, etc., to understand distributions and relationships.\n",
    "- Summary Statistics: Calculating mean, median, mode, standard deviation, and correlation to gain insights into the dataset.\n",
    "- Detecting Outliers: Identifying values that deviate significantly from the rest of the data.\n",
    "- Assessing Data Types and Structure: Checking data types, unique values, and identifying missing values."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d681a602-8dcd-43df-8063-b5912eeae510",
   "metadata": {},
   "source": [
    "#### Q2: How many unique transactions are in the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a637f61a-26e5-4ee6-9f79-5c26778252a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_transactions = events['transactionid'].nunique()\n",
    "unique_transactions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f990723-4ece-4206-8bad-265a3d293cba",
   "metadata": {},
   "source": [
    "#### Q3: What is the distribution of transactions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14b70e1a-a54b-42eb-ba4e-d5641da7dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "transaction_counts = events[events['transactionid'].notnull()]['transactionid'].value_counts()\n",
    "\n",
    "transaction_counts.plot(kind='hist', bins=30, color='black')\n",
    "plt.title('Distribution of Transactions')\n",
    "plt.xlabel('Number of Events per Transaction')\n",
    "plt.ylabel('Frequency')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "365066a7-5136-4931-a544-918df526dc8e",
   "metadata": {},
   "source": [
    "#### Q4: How many events happen on average per day?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b898e0-14cc-4467-b6b5-2356d5e08830",
   "metadata": {},
   "outputs": [],
   "source": [
    "events_per_day = events.groupby(events['event_date']).size()\n",
    "avg_events_per_day = events_per_day.mean()\n",
    "\n",
    "events_per_day.plot(kind='line', title='Events per Day', color='black')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Number of Events')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5632c1a-b1fb-4637-a994-c3980853cede",
   "metadata": {},
   "source": [
    "#### Q5: Calculate the count of each unique property corresponding to \"addtocart\" items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a7dea3-50fe-4cbb-980f-509df52956dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4963c33c-b716-4e86-8344-ac4130bb8246",
   "metadata": {},
   "outputs": [],
   "source": [
    "item_properties"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe5d3b2-77bb-4bda-9e1e-7e9ca166b919",
   "metadata": {},
   "outputs": [],
   "source": [
    "addtocart_events = events[events['event'] == 'addtocart']\n",
    "addtocart_events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4845d40-27c1-4fbc-bc52-df7d7f6700e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "addtocart_events = events[events['event'] == 'addtocart']\n",
    "merged_data = pd.merge(addtocart_events, item_properties, on='itemid', how='left')\n",
    "merged_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7eb185b-6aa3-45d7-b226-3309d87d7bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "property_counts = merged_data['property'].value_counts()\n",
    "print(property_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f992fa1a-e3cf-4575-a08b-f88a87d4a7f4",
   "metadata": {},
   "source": [
    "#### Q6: What is the Spearman correlation between the number of \"view\" events and the number of \"addtocart\" events per item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "511d0115-56f4-4798-b728-c0cd684d8221",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter 'view' and 'addtocart' events\n",
    "view_events = events[events['event'] == 'view']\n",
    "addtocart_events = events[events['event'] == 'addtocart']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c5003f4-f645-4d89-a95c-b2264c4a6b24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Item count\n",
    "view_counts = view_events['itemid'].value_counts()\n",
    "addtocart_counts = addtocart_events['itemid'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2607b63-0086-49ce-b45d-602ff0db6701",
   "metadata": {},
   "outputs": [],
   "source": [
    "view_df = view_counts.reset_index().rename(columns={'count': 'view_count'})\n",
    "addtocart_df = addtocart_counts.reset_index().rename(columns={'count': 'addtocart_count'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db43961d-f262-4d51-8d71-e64df330577e",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = pd.merge(view_df, addtocart_df, on='itemid', how='inner')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8045e138-5baf-4055-b4c4-6991774516ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_corr = merged_df['view_count'].corr(merged_df['addtocart_count'],\\\n",
    "                                             method='spearman')\n",
    "spearman_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b03989-1d8d-4264-be34-14952acc3bdf",
   "metadata": {},
   "source": [
    "#### Q7: What is the Pearson correlation between the number of \"view\" events and the number of \"addtocart\" events per item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5621b346-f6e2-4523-beba-86fd061fa5c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_corr = merged_df['view_count'].corr(merged_df['addtocart_count'], \\\n",
    "                                            method='pearson')\n",
    "pearson_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8badf06-dea9-4672-9851-79440d627c9d",
   "metadata": {},
   "source": [
    "#### Q8: What is the Kendall's Tau correlation between the number of \"view\" events and the number of \"addtocart\" events per item?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26a2e88a-8c57-4338-84c5-bcaea5f08696",
   "metadata": {},
   "outputs": [],
   "source": [
    "kendall_tau_corr = merged_df['view_count'].corr(merged_df['addtocart_count'], \\\n",
    "                                                method='kendall')\n",
    "kendall_tau_corr"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0b38a0-6193-40b9-9206-e01d6dd9e6ce",
   "metadata": {},
   "source": [
    "#### Q9: Create a scatter plot with ordinary least squares' trend line to show correlation between the number of \"view\" events and the number of \"addtocart\" events per item. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed20d0ed-e833-4318-b4aa-a8bebdac2fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "# Create a scatter plot with OLS trendline\n",
    "fig = px.scatter(merged_df, x=\"view_count\", y=\"addtocart_count\", \\\n",
    "                 trendline=\"ols\", trendline_color_override=\"red\")\n",
    "\n",
    "# Save the figure as an HTML file\n",
    "fig.write_html('scatter_plot_with_ols_trendline.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18b79ef-f883-4f9c-aeea-1ed3655229fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
